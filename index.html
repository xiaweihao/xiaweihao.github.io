<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<!-- <meta name="google-site-verification" content="Ep23zzf6RP-Lk5jA8WMBAoffjZVHoEsGWOyZqE6QHjA" /> -->
	
<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/jpg" href="images/seal_icon.jpg">
  <title>Weihao Xia</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Weihao Xia</name>
              </p>
              <p>I am a research assistant at <a href="https://www.tsinghua.edu.cn/publish/thu2018en/index.html">Tsinghua University</a>.</p>

              <p>I am interested in computer vision, computer graphic, and human–computer interaction. I am currently working on controllable, interpretable, and generalizable visual contents generation, especially generating 2D images, videos, or 3D shapes from multi-modal information (e.g., sketches, labels, or textual descriptions). </p>

              <p>I’m also concerned about the Data Bias and Efficiency and AI Fairness, Privacy, and Transparency in generation tasks.</p>

              <p align=center>
                 <a href="mailto:weihaox@outlook.com">Email</a> &nbsp/&nbsp
                <a href="docs/cv_weihao.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=Egqp5AMAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/weihaox/">Github</a>
              </p>
            </td>
            <td width="33%">
              <img style="width: 80%" src="docs/images/profile.jpg" alt="PontTuset">
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Research Statement</heading>
                <p> I am interested in developing human-centeric general intelligent systems that are </p>
                <p class="content">
                  <ul>
                    <li><b>controllable</b> for naive users to create, edit, share, and use visual contents</li>
                    <li><b>interpretable</b> about the components, principle, and predictions </li>
                    <li><b>generalizable</b> to real-world applications such as different domains with limited data</li>
                    <li><b>trustworthy</b> with no risks on fairness, privacy, and ethics</li>
                  </ul>
                </p>

                <p>The ultimate vision of my research is to manifest the physical world through imagination.</p>

              </td>
            </tr>
          </tbody>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>News</heading>
            <p><strong>[01/2021] Our survey on GAN Inversion is available.</strong> </p>
            <p>[07/2020] One paper is accepted to ACM MM 2020 (poster). </p>
            <p>[06/2020] One Paper is accepted to T-CSVT. </p>
            <p>[05/2020] One Paper is accepted to Neural Networks. </p>
          </td>
        </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Education</heading>
            <p>
            <strong>Tsinghua University</strong><br />
            M.E. in Control Engineering, Department of Automation &bull; Sep. 2016 - Jul. 2019 <br />
            </p>

            <p>
            <strong>Sun Yat-Sen University</strong><br />
            B.E. in Automation, School of Information Science and Technology &bull; Sep. 2012 - Jul. 2016 <br />
            </p>

          </td>
        </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Research Experience</heading>
            <p>
            <strong>Tsinghua University</strong><br />
            Research Assistant &bull; Dec. 2020 - Now <br />
            Adviser: Professor <a href="https://www.sz.tsinghua.edu.cn/fg3/105062.jhtml">Yujiu Yang</a> <br/>
            </p>
            <p>
            <strong>MediaLab, HUAWEI Technologies Co., Ltd.</strong><br />
            3D Vision Algorithm Engineer &bull; Oct. 2019 - Dec. 2020 <br />
            </p>
            <p>
            <strong>Tsinghua University</strong><br />
            Research Assistant &bull; Jun. 2019 - Oct. 2019 <br />
            Adviser: Professor <a href="https://www.sz.tsinghua.edu.cn/fg3/105062.jhtml">Yujiu Yang</a> <br/>
            </p>
            <p>
            <strong>SenseTime Group Limited</strong><br />
            R&D Intern &bull; Oct. 2017 - Mar. 2018 <br />
            Adviser: Dr. <a href="http://wenxiusun.com/">Wenxiu Sun</a><br/>
            </p>

          </td>
        </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <td width="100%" valign="middle">
              <heading>Manuscript</heading>
            </td>

        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
          <td width="30%"><img src="projects/ganinversion/pic/Illustration.png" alt="PontTuset"  width="350" style="border-style: none">
            <td width="70%" valign="middle">
                <papertitle><a href="https://arxiv.org/abs/2101.05278">GAN Inversion: A Survey.</a></papertitle>
                <br>
                <b>Weihao</b>, Yulun Zhang, Yujiu Yang, Jing-Hao Xue, Bolei Zhou, Ming-Hsuan Yang.
                <br>
                arXiv.2101.05278 preprint
                <br>
                <p>
                  <a href="https://arxiv.org/pdf/2101.05278.pdf">Paper</a> /
                  <a href="https://github.com/weihaox/awesome-image-translation/blob/master/awesome-gan-inversion.md">Project</a>
                </p>
                <p>
                a comprehensive overview of GAN inversion methods with an emphasis on algorithms and applications.
                </p>
            </td>
          </tr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
          <td width="30%"><img src="projects/tedigan/pic/control_mechanism.jpg" alt="PontTuset"  width="350" style="border-style: none">
            <td width="70%" valign="middle">
                <papertitle><a href="https://arxiv.org/abs/2012.03308">TediGAN: Text-Guided Diverse Face Image Generation and Manipulation.</a></papertitle>
                <br>
                <b>Weihao</b>, Yujiu Yang, Jing-Hao Xue, Baoyuan Wu.
                <br>
                arXiv.2012.03308 preprint
                <br>
                <p>
                  <a href="https://arxiv.org/pdf/2012.03308.pdf">Paper</a> /
                  <a href="https://xiaweihao.com/projects/tedigan/">Project</a> /
                  <a href="https://github.com/weihaox/TediGAN">Code</a> /
                  <a href="https://github.com/weihaox/Multi-Modal-CelebA-HQ">Data</a> /
                  <a href="https://youtu.be/L8Na2f5viAM">Video</a> 
                </p>
                <p>
                a novel method that unifies two different tasks (text-guided image generation and manipulation) into the same framework and achieves high accessibility, diversity, controllability, and accurateness for facial image generation and manipulation.
                </p>
            </td>
          </tr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Publication</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
          <td width="30%"><img src="projects/interpgaze/pic/control_mechanism_terse.jpg" alt="PontTuset" width="350" style="border-style: none">
            <td width="70%" valign="middle">
                <papertitle><a href="https://arxiv.org/abs/2010.04513">InterpGaze: Controllable Continuous Gaze Redirection.</a></papertitle>
                <br>
                <b>Weihao Xia</b>, Yujiu Yang, Jing-Hao Xue, Wensen Feng.
                <br>
                ACM Multimedia (<b>ACM-MM</b>, acceptance rate 27.8%), 2020.
      
                <br>
                <p>
                  <a href="https://arxiv.org/abs/2010.04513">Paper</a> /
                  <a href="https://xiaweihao.com/projects/tedigan/interpgaze">Project</a> /
                  <a href="https://github.com/weihaox/InterpGaze">Code and Data</a> 
                </p>
                <p>
                we present a novel method that works on both precise redirection and continuous interpolation. With the well-disentangled and hierarchically-organized latent space, we can adjust the order and strength of each attribute by altering the additional control vector. 
                </p>
            </td>
        </tr>

        <tr>
          <td width="30%"><img src="projects/da-iqa/pic/framework.jpg" alt="PontTuset" width="350" style="border-style: none">
            <td width="70%" valign="middle">
              <p>
                <papertitle><a href="https://doi.org/10.1109/TCSVT.2020.3002662">Domain Fingerprints for No-reference Image Quality Assessment</a></papertitle>
                <br>
                <b>Weihao Xia</b>, Yujiu Yang, Jing-Hao Xue, Jing Xiao.
                <br>
                IEEE Transactions on Circuits and Systems for Video Technology (<b>T-CSVT</b>, JCR Q1, IF = <span style="color: red; "><b>4.046</b></span>), 2020.
                <br>
              </p>
              <p>
                <a href="https://doi.org/10.1109/TCSVT.2020.3002662">Paper</a> /
                <a href="data/MICCAI2019.bib">Project</a>
              </p>
              <p>
              we  introduce the concept of domain fingerprint to the NR-IQA field, which is learned from image collections of different degradations and then used as the unique characteristics to identify the degradation sources and assess the quality of the image.
              </p>
            </td>
        </tr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            <td width="30%"><img src="projects/dcm2it/pic/network.png" alt="PontTuset" width="350" style="border-style: none">
              <td width="70%" valign="middle">
                  <papertitle><a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608020302641">Unsupervised Multi-Domain Multimodal Image-to-Image Translation with Explicit Domain-Constrained Disentanglement.</a></papertitle>
                  <br>
                  <b>Weihao Xia</b>, Yujiu Yang, Jing-Hao Xue.
                  <br>
                  Elsevier Neural Networks (<b>NN</b>, JCR Q1, IF= <span style="color: red; "><b>5.789</b></span>), 2020.
                  <br>
                  <p>
                  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608020302641">Paper</a> /
                  <a href="https://xiaweihao.com/projects/tedigan/dcmit">Project</a> /
                  <a href="https://github.com/weihaox/DCMIT">Code</a> 
                  </p>
                  <p>
                  explicit disentanglement learning constraints with domain supervision to learn explicit disentangled representations and avoid the confusion of content and style.
                  </p>
              </td>
          </tr>

        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  Updated January 2021.
                </font>
              </p>
              <p align="right">
                <font size="2">
                  Special thanks to <a href="https://jonbarron.info/">Jon Barron</a> for website template.
                </font>
              </p>

        </table>

        <script type="text/javascript">
          try {
            var pageTracker = _gat._getTracker("UA-7580334-1");
            pageTracker._trackPageview();
          } catch (err) {}
        </script>
        </td>
    </tr>
  </table>
</body>

</html>