<!DOCTYPE html>
<html>

<head>
<meta charset='utf-8' />
<meta http-equiv="X-UA-Compatible" content="chrome=1" />
<meta name="description" content="Weihao Xia‘s Homepage" />
<meta name="keywords" content="Deep Learning, Computer Vision, Image Translation, Restoration and Enhancement" />
<!-- <link rel="stylesheet" type="text/css" href="stylesheet.css"/> -->
<link rel="stylesheet" type="text/css" href="jemdoc.css"/>
<title>Weihao Xia - Homepage</title>
</head>
<body>


<div id="layout-content" style="margin-top:25px">
<a href="https://github.com/weihaox" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#FD6C6C; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>


<div id="header">
	<!-- <h1>Weihao Xia</h1> -->
    <!-- <h1>Weihao Xia (夏伟浩)</h1> -->
    <h1>Weihao Xia</h1><p><font size=+2> &#22799;&#20255;&#28009;</font></p>  
    <p>Research Assistant @ Tsinghua University</br>
	<b>Email</b>: <i>weihaox</i> at outlook.com  or <i>xiawh16</i> at gmail.com (optional) </br>
    <a href="http://github.com/weihaox">GitHub</a>&nbsp;&nbsp;|&nbsp;&nbsp;
    <a href="./docs/cv_weihao.pdf">CV</a>&nbsp;&nbsp;|&nbsp;&nbsp;
    <a href="https://scholar.google.com/citations?view_op=list_works&hl=zh-CN&user=Egqp5AMAAAAJ">Google Scholar</a>&nbsp;&nbsp;
    <!-- |&nbsp;&nbsp;
    <a href="https://weihaox.com/fun/">Blog</a>&nbsp;&nbsp; |&nbsp;&nbsp;
    <a href="http://orcid.org/0000-0003-0087-3525">ORCID</a>&nbsp;&nbsp;|&nbsp;&nbsp;
    <a href="https://dblp.uni-trier.de/pers/hd/x/Xia:Weihao">DBLP</a>&nbsp;&nbsp;|&nbsp;&nbsp; -->

     <!--<p><span style="color:rgb(225,65《105)"><b>Currently, I am looking for a Ph.D. position. If you find my work matching with your research area and intend to provide me a potential Ph.D. position, please contact me and let's make a difference!</b></span></p>-->
</div>  	
        <h2>Research Interest and Prospect</h2>
        <p>
        I am interested in deep learning, generative model, and explainable artificial intelligence. Much of my research is about <a href="http://xiaweihao.com/awesome-image-translation/" target="_blank">image translation</a> and generation. 
        The ultimate vision of my research is to manifest the physical world through imagination.
        I am currently working on generating 2D images, videos or 3D shapes from multi-modal information (\emph{e.g.}, sketches or textual descriptions) by discovering the interpretable directions in the latent space of a pretrained model.
        </p>

		<h2>Biography</h2>

        <p>
        I received my master degree in Control Engineering from School of Information Science and Technology, <a href="https://www.tsinghua.edu.cn/publish/thu2018en/index.html" target="_blank">Tsinghua University (THU)</a>, under the supervision of <a href="https://www.sz.tsinghua.edu.cn/fg3/105062.jhtml" target="_blank">Prof. Yujiu Yang</a> in both Intelligent Computing Team and Shenzhen Key Laboratory of Information Science and Technology. 
        Before that, I received my bachelor degree from School of Information Science and Technology in <a href="http://www.sysu.edu.cn/2012/en/about/about01/index.htm" target="_blank">Sun Yat-Sen University (SYSU)</a>.
		</p>	

        <p>
        I am currently  a research assistant at Tsinghua University, working with my master advisor <a href="https://www.sz.tsinghua.edu.cn/fg3/105062.jhtml" target="_blank">Prof. Yujiu Yang</a> .
        </p>

        <h2>Education</h2>
            <ul style="padding-left: 10px">
                <li>M. E. Degree in Control Engineering, Department of Automation, Tsinghua University, Sep. 2016 ~ Jul. 2019</li>
                <li>B. S. Degree in Automation, School of Information Science and Technology, Sun Yat-Sen University, Sep. 2012 ~ Jul. 2016</li>
            </ul>

		<h2>Research and Work Experience</h2>

        <table id="tbResearch" border="0" width="100%">
            <tbody>
                <tr>
                    <td>Research Assistant</td><td>Tsinghua University</td><td>2010-12 ~ Now</td>
                </tr>
                <tr>
                    <td>3D Vision Algorithm Engineer</td><td> 2012 Labs, Huawei Technologies Co., Ltd.</td><td>2019-10 ~ 2020-12</td>
                </tr>
                <tr>
                    <td>Research Assistant</td><td>Tsinghua University</td><td>2019-07 ~ 2019-10</td>
                </tr>
               <tr>
                    <td>Part-time Algorithm Engineer</td><td> 2012 Labs, Huawei Technologies Co., Ltd.</td><td>2018-06 ~ 2018-10</td>
                </tr>
                <tr>
                    <td>Part-time R&D Engineer</td><td>SenseTime Group Limited</td><td>2017-10 ~ 2018-03</td>
                </tr>
            </tbody>
        </table>
	
		<h2>Publications</h2> 
			<ul>
                <li>
                <b>J1: Unsupervised Multi-Domain Multimodal Image-to-Image Translation with Explicit Domain-Constrained Disentanglement</b> </br>
                <b>Weihao Xia</b>, Yujiu Yang, Jing-Hao Xue</br> 
                Elsevier Neural Networks (NN, JCR Q1, IF= 5.789), vol. 131, pp. 50-63, Nov., 2020.</br>
                [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608020302641" target="_blank">PDF</a>] [<a href="https://github.com/weihaox/DCMIT" target="_blank">Code</a>] 
                </li>

                <li>
                <b>J2: Domain Fingerprints for No-reference Image Quality Assessment</b></br>
                <b>Weihao Xia</b>, Yujiu Yang, Jing-Hao Xue, Jing Xiao</br>
                IEEE Transactions on Circuits and Systems for Video Technology (TCSVT, JCR Q1, IF=4.046), 2020.</br> 
                [<a href="https://doi.org/10.1109/TCSVT.2020.3002662" target="_blank">PDF</a>]
                </li> 

                <li>
                <b>C1: InterpGaze: Controllable Continuous Gaze Redirection</b></br>
                <b>Weihao Xia</b>, Yujiu Yang, Jing-Hao Xue, Wensen Feng</br>
                ACM Multimedia (ACM-MM, acceptance rate 27.8%), 2020.</br> 
                [<a href="\href{https://dl.acm.org/doi/abs/10.1145/3394171.3413868" target="_blank">PDF</a>] [<a href="\href{https://github.com/weihaox/InterpGaze" target="_blank">Code & Data</a>] [<a href="\href{https://youtu.be/Tis7YecUH34" target="_blank">Video</a>]
                </li> 

                <li>
                <b>T1: Image Restoration and Image Quailty Assessment via Deep Learning</b></br> 
                <b>Weihao Xia</b></br> 
                Thesis Submitted to Tsinghua University in partial fulfillment of the requirement for the professional degree of Master of Engineering. May 2019.
                </li>

			</ul> 

        <h2>Preprints</h2>
            <ul>

                <li>
                <b>TediGAN: Text-Guided Diverse Face Image Generation and Manipulation</b></br>
                <b>Weihao Xia</b>, Yujiu Yang, Jing-Hao Xue, Baoyuan Wu</br>
                arXiv: 2012.03308, Oct. 2020.</br> 
                [<a href="http://arxiv.org/abs/1911.00426" target="_blank">PDF</a>] [<a href="https://github.com/weihaox/TediGAN" target="_blank">Code</a>] [<a href="https://github.com/weihaox/Multi-Modal-CelebA-HQ" target="_blank">Multi-Modal-CelebA-HQ Dataset</a>] [<a href="https://youtu.be/L8Na2f5viAM" target="_blank">Video</a>] 
                </li> 


                <li>
                <b>SR-Net: Cooperative Image Segmentation and Restoration in Adverse Environmental Conditions</b></br>
                <b>Weihao Xia</b>, Zhanglin Cheng, Yujiu Yang</br>
                arXiv: 1911.00679, Aug. 2019.</br>
                [<a href="http://arxiv.org/abs/1911.00679" target="_blank">PDF</a>] [<a href="http://arxiv.org/abs/1911.00679"  target="_blank">Supplementary Material</a>] [<a href="projects/SR-Net" target="_blank">Project</a>] [<a href="https://github.com/weihaox/SR-Net" target="_blank">Code</a>] [<a href="https://github.com/weihaox/SR-Net/data_generator" target="_blank">Data</a>]
                </li>

                <li>
                <b>Cali-Sketch: Stroke Calibration and Completion for High-Quality Face Image Generation from Poorly-Drawn Sketches</b></br>
                <b>Weihao Xia</b>, Yujiu Yang, Jing-Hao Xue</br>
                arXiv: 1911.00426, Mar. 2019.</br> 
                [<a href="http://arxiv.org/abs/1911.00426" target="_blank">PDF</a>] [<a href="projects/cali-sketch" target="_blank">Project</a>] 
                </li> 
              </ul>

        <h2>Teaching</h2>
            <ul>
                <li>Teaching Assistant, <b>Selected Topics on Intelligent Information Processing</b>, Tsinghua University, Fall 2017.</li>
            </ul>

        <h2>Acknowledgements</h2>
                <ul>
                    <li>
                    Alma Mater: 
                    <a href="https://www.tsinghua.edu.cn/publish/thu2018/index.html" target="_blank">Tsinghua University</a> (THU), 
                    <a href="http://www.homepages.ucl.ac.uk/~ucakjxu/" target="_blank">Sun Yat-Sen University</a> (SYSU) 
                    </li>                        
                    <li>
                    Collaborators:
                    <a href="https://www.sz.tsinghua.edu.cn/fg3/105062.jhtml" target="_blank">Prof. Yujiu Yang</a> (THU), 
                    <a href="http://www.homepages.ucl.ac.uk/~ucakjxu/" target="_blank">Prof. Jing-Hao Xue (J.-H. Xue)</a> (UCL)
                    </li>
                </ul>

         <h2>Miscellaneous</h2>
            <ul>
                <li>
                Resources:       
                <a href="http://xiaweihao.com/awesome-image-translation/" target="_blank">awesome image translation</a>,
                <a href="http://xiaweihao.com/awesome-neural-rendering/" target="_blank">awesome neural rendering</a>,
                <a href="https://github.com/weihaox/awesome-image-translation/blob/master/awesome-gan-inversion.md" target="_blank">awesome gan inversion</a>,
                <a href="https://github.com/weihaox/awesome-neural-rendering/blob/master/awesome-clothed-human.md" target="_blank">awesome clothed human</a>,
                <a href="https://xiaweihao.com/awesome-image-translation/infer-physical-world-from-images" target="_blank">inferring physical world from images</a>
                </li> 
                <li>
                Codes:
                <a href="https://github.com/weihaox" target="_blank">github.com/weihaox</a>
                </li>                      
            </ul> 

<!--        <h2>Skills</h2>
            <ul>
                <li>Programming: Python, Matlab, Go, C/C++.</li>
                <li>Frameworks: PyTorch, TensorFlow.</li>
            </ul> -->
	
	<div id="footer">
		<p><script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=200&t=n&d=wZIlU9uB0oVvrTs5UqpK79Z3d7hEQxVRpP3dD0iSRTs"></script></p>
		
		<p>Last update: Dec. 10, 2020.</p>
	</div>

  </body>
</html>
