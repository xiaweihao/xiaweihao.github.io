<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Unsupervised Multi-Domain Multimodal Image-to-Image Translation with Explicit Domain-Constrained Disentanglement</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="Video-Inpainting.&gt;
&lt;meta name=" keywords"="">

<!-- Fonts and stuff -->
<link href="./cali-sketch/project.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="./css/project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./projects/cali-sketch/iconize.css">
<script type="text/javascript" async="" src="./projects/cali-sketch/ga.js.download"></script><script async="" src="./cali-sketch/prettify.js.download"></script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$']]},
        messageStyle: "none"
    });
</script>

<script type="text/javascript">
            
            var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-22940424-1']);
            _gaq.push(['_trackPageview']);
            
            (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
            })();
            
</script>

</head>

<body>
  <div id="content">
    <div id="content-inner">
      
      <div class="section head">
    <h1>Unsupervised Multi-Domain Multimodal Image-to-Image Translation with Explicit Domain-Constrained Disentanglement</h1>

    <div class="authors">
      <a href="https://xiaweihao.github.io/">Weihao Xia<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      <a>Yujiu Yang<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      <a href="http://www.homepages.ucl.ac.uk/~ucakjxu/">Jing-Hao Xue<sup>2</sup></a>
    </div>

    <div class="affiliations">
      <sup>1</sup> <a>Tsinghua University</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br>
      <sup>2</sup> <a>Department of Statistical Science, University College London</a>
    </div>

    <div class="venue"></div>
  </div>
  

  <div class="section abstract">
    <h2>Abstract</h2>
    <br>
    <p>
      No-reference image quality assessment (NR-IQA) is a fundamental yet challenging task in low-level computer vision community. It is the task to predict the perceptual quality of an image with unknown distortion information and requires to be highly correlated with human visual perception. The difficulty is particularly pronounced for the limited information, for which the corresponding reference for comparison is typically absent. Various feature extraction mechanisms have been leveraged to boost the performance from natural scene statistics to deep features. However, these methods treat images of different degradations as the same and the representations of distortions are under-exploited. Furthermore, since images with different distortion may share very similar quality scores, identifying the distortion type should be an important part for NR-IQA, which is rarely addressed in the previous methods. In this work, we propose the domain-aware no-reference image quality assessment (DA-NR-IQA), which first exploits the distorted representation of specific degradation for image quality assessment. Extensive experiments show that the proposed DA-NR-IQA performs statistically better than all the other state-of-the-art NR-IQA methods.
    </p>
      </div>
    
    <div class="section materials">
  <h2>Materials</h2>
  <center>
    <ul>
          <li class="grid">
        <div class="griditem">
    <a href="./docs/DA-IQA.pdf" target="_blank" class="imageLink"><img src="./projects/da-iqa/paper.png" border="0" width="50%"></a><br>
    </div>
        </li>
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      
      <li class="grid">
      <div class="griditem">
        <a href=><img src="./projects/da-iqa/code.png"></a><br>
     </div>
        </li>
    
      </ul>
      </center>
      </div>

    <div class="section framework">
    <h2>Framework</h2>
    <br>
        <center><img src="./projects/da-iqa/framework.png" border="0" width="95%"></center>
    <br>
   <p>
      The framework of the proposed DA-NR-IQA. Given a dataset that contains several collections of images with different degradations (a), refer as $n$ domains, we first randomly select a distorted image together with its specific domain label from a certain domain $I_d^i \in \mathcal{D}_{i}$, the generator of Domain-Aware Image Restoration Network (b) aims to separate the distortion $d$ from $I_d$ to get the restoration $I_r$ while the discriminator tries to distinguish if the input image is real or fake and domain discriminator recognizes the category. The original distorted image and its discrepancy map are fed into Discrepancy-Guided Quality Regression Network (c). Features are extracted by a CNN and fused as difference, concatenation with high-level semantic vector. The double arrows means the corresponding module are Siamese Network. Then the fused feature is regressed to a patchwise quality and weight estimation.
    </p>
    </div>

        <div class="section visualization">
            <h2>Results</h2>
            <br>
                <center><img src="./projects/da-iqa/result.png" border="0" width="80%"></center>
        </div>

        
<br>

<div class="section citation">
    <h2>Citation</h2>
    <div class="section bibtex">
      <pre>@InProceedings{Xia_2019_Explicit,
author = {Xia, Weihao and Yang, Yujiu and Xue, Jing-Hao},
title = {Domain-Aware No-Reference Image Quality Assessment},
month = {June},
year = {2019}
}</pre>
      </div>
      </div>



</div></div></body></html>